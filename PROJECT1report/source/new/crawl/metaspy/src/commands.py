import subprocess
from time import time
import typer
from dotenv import load_dotenv
from rich import print as rprint
import os
import glob
import json
import networkx as nx
import matplotlib.pyplot as plt


from .facebook.account.account_friend import AccountFriend
from .facebook.login import FacebookLogIn
from .logs import Logs
from .repository import crawlerqueue_repository
from .scripts.urlid import get_account_id
from typing_extensions import Annotated
from .facebook.account.account_friend_layer import AccountFriendLayer
from .analytics.graph import create_relationship_graph
444
load_dotenv()
logs = Logs()
app = typer.Typer(
    pretty_exceptions_enable=False,
)

""" Analytics """

def create_graph_from_friends_data(data_dir):
    """
    Create a graph of connections between users based on their friends data
    from a specific friends_data directory
    
    Args:
        data_dir (str): Path to the friends_data directory
    """
    G = nx.DiGraph()
    
    # ƒê·ªçc file JSON ch√≠nh trong th∆∞ m·ª•c
    json_files = glob.glob(os.path.join(data_dir, "*.json"))
    if not json_files:
        rprint(f"Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu n√†o trong th∆∞ m·ª•c {data_dir}")
        return None
    
    # ƒê·ªçc d·ªØ li·ªáu t·ª´ file JSON
    for json_file in json_files:
        with open(json_file, 'r', encoding='utf-8') as f:
            try:
                data = json.load(f)
                
                # Th√™m node g·ªëc
                root_user = data.get("root_user") or data.get("account_id")
                if not root_user:
                    continue
                
                # X·ª≠ l√Ω d·ªØ li·ªáu ch√≠nh
                main_data = data.get("data", data)
                if not main_data:
                    continue
                
                # Th√™m node g·ªëc v√†o ƒë·ªì th·ªã
                G.add_node(root_user, label=root_user)
                
                # X·ª≠ l√Ω danh s√°ch b·∫°n b√®
                process_friends_data(G, main_data, root_user)
                
            except json.JSONDecodeError:
                rprint(f"Kh√¥ng th·ªÉ ƒë·ªçc file {json_file}")
                continue
    
    if len(G.nodes) == 0:
        rprint("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ v·∫Ω ƒë·ªì th·ªã")
        return None
    
    # V·∫Ω ƒë·ªì th·ªã
    plt.figure(figsize=(12, 10))
    pos = nx.spring_layout(G, k=0.3)
    labels = {node: G.nodes[node].get('label', node) for node in G.nodes()}
    nx.draw(G, pos, labels=labels, with_labels=True, node_size=800, 
            node_color='skyblue', font_size=8, font_weight='bold',
            edge_color='gray', width=0.5, arrows=True)
    
    plt.title(f"ƒê·ªì th·ªã quan h·ªá b·∫°n b√® t·ª´ {data_dir}")
    plt.show()
    
    return G

def process_friends_data(G, data, parent_id):
    """
    ƒê·ªá quy x·ª≠ l√Ω d·ªØ li·ªáu b·∫°n b√® v√† th√™m v√†o ƒë·ªì th·ªã
    
    Args:
        G (nx.DiGraph): ƒê·ªì th·ªã
        data (dict): D·ªØ li·ªáu b·∫°n b√®
        parent_id (str): ID c·ªßa node cha
    """
    friends = data.get("friends", [])
    if not friends:
        return
    
    for friend in friends:
        # L·∫•y ID c·ªßa b·∫°n b√®
        friend_id = friend.get("username") or friend.get("uid") or friend.get("id")
        if not friend_id:
            continue
        
        # T√™n hi·ªÉn th·ªã
        friend_name = friend.get("name", friend_id)
        
        # Th√™m node b·∫°n b√® v√†o ƒë·ªì th·ªã
        G.add_node(friend_id, label=friend_name)
        
        # Th√™m c·∫°nh k·∫øt n·ªëi
        G.add_edge(parent_id, friend_id)
        
        # X·ª≠ l√Ω d·ªØ li·ªáu b·∫°n b√® c·ªßa b·∫°n b√® (n·∫øu c√≥)
        friends_data = friend.get("friends_data")
        if friends_data:
            process_friends_data(G, friends_data, friend_id)

@app.command()
def graph() -> None:
    """Create a graph of connections between Person objects based on their Friends"""
    create_relationship_graph()


@app.command()
def graph_friends_data() -> None:
    """V·∫Ω ƒë·ªì th·ªã quan h·ªá t·ª´ d·ªØ li·ªáu trong th∆∞ m·ª•c friends_data"""
    # T√¨m t·∫•t c·∫£ c√°c th∆∞ m·ª•c c√≥ d·∫°ng friends_data_*
    data_dirs = glob.glob("friends_data_*")
    
    if not data_dirs:
        rprint("‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c d·ªØ li·ªáu n√†o c√≥ d·∫°ng friends_data_*")
        return
    
    rprint("[bold]Danh s√°ch th∆∞ m·ª•c d·ªØ li·ªáu:[/bold]")
    for i, dir_name in enumerate(data_dirs, 1):
        # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ th∆∞ m·ª•c
        json_files = glob.glob(os.path.join(dir_name, "*.json"))
        num_files = len(json_files)
        
        # L·∫•y th√¥ng tin v·ªÅ th·ªùi gian t·∫°o th∆∞ m·ª•c
        try:
            creation_time = os.path.getctime(dir_name)
            from datetime import datetime
            time_str = datetime.fromtimestamp(creation_time).strftime("%d/%m/%Y %H:%M:%S")
        except:
            time_str = "Kh√¥ng x√°c ƒë·ªãnh"
            
        rprint(f"{i}. [bold]{dir_name}[/bold] - {num_files} file - T·∫°o l√∫c: {time_str}")
    
    # Cho ph√©p ng∆∞·ªùi d√πng ch·ªçn th∆∞ m·ª•c
    choice = typer.prompt(
        "Ch·ªçn s·ªë th·ª© t·ª± th∆∞ m·ª•c ƒë·ªÉ v·∫Ω ƒë·ªì th·ªã",
        type=int
    )
    
    # Ki·ªÉm tra l·ª±a ch·ªçn h·ª£p l·ªá
    if choice < 1 or choice > len(data_dirs):
        rprint("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá")
        return
    
    selected_dir = data_dirs[choice - 1]
    rprint(f"ƒêang v·∫Ω ƒë·ªì th·ªã t·ª´ d·ªØ li·ªáu trong th∆∞ m·ª•c [bold]{selected_dir}[/bold]...")
    
    # V·∫Ω ƒë·ªì th·ªã
    time_start = time()
    graph = create_graph_from_friends_data(selected_dir)
    time_end = time()
    
    if graph:
        rprint(f"‚úÖ V·∫Ω ƒë·ªì th·ªã th√†nh c√¥ng sau {time_end - time_start:.2f} gi√¢y")
        rprint(f"   - S·ªë node: {len(graph.nodes())}")
        rprint(f"   - S·ªë c·∫°nh: {len(graph.edges())}")
    else:
        rprint("‚ùå Kh√¥ng th·ªÉ v·∫Ω ƒë·ªì th·ªã t·ª´ d·ªØ li·ªáu trong th∆∞ m·ª•c n√†y")


@app.command()
def friend_crawler(
    user_id: Annotated[str, typer.Argument(help="Facebook user id")]
) -> None:
    max_friends_input = typer.prompt(
        "Nh·∫≠p s·ªë l∆∞·ª£ng b·∫°n b√® c·∫ßn thu th·∫≠p (nh·∫•n Enter ƒë·ªÉ thu th·∫≠p t·∫•t c·∫£)",
        default="",
        type=str,
        show_default=False
    )
    max_friends = None
    if max_friends_input.strip():
        try:
            max_friends = int(max_friends_input)
            if max_friends <= 0:
                typer.echo("S·ªë l∆∞·ª£ng b·∫°n b√® ph·∫£i l·ªõn h∆°n 0. S·∫Ω thu th·∫≠p t·∫•t c·∫£ b·∫°n b√®.")
                max_friends = None
        except ValueError:
            typer.echo("ƒê·∫ßu v√†o kh√¥ng h·ª£p l·ªá. S·∫Ω thu th·∫≠p t·∫•t c·∫£ b·∫°n b√®.")
            max_friends = None

    rprint(f"B·∫Øt ƒë·∫ßu thu th·∫≠p d·ªØ li·ªáu t·ª´ {user_id}")
    scraper = AccountFriend(user_id=user_id, max_friends=max_friends, crawler=True)
    
    time_start = time()
    scraper.pipeline()
    time_end = time()
    
    if scraper.is_pipeline_successful:
        rprint(f"‚úÖ Thu th·∫≠p th√†nh c√¥ng sau {time_end - time_start} gi√¢y ‚úÖ")
        
        users = crawlerqueue_repository.get_crawler_queues_status_false()
        while len(users) > 0:
            for user in users:
                user_id = get_account_id(user.url)
                rprint(f"ƒêang thu th·∫≠p d·ªØ li·ªáu t·ª´ {user_id}")
                scraper = AccountFriend(user_id=user_id, max_friends=max_friends, crawler=True)
                scraper.pipeline()

                if scraper.is_pipeline_successful:
                    crawlerqueue_repository.delete_crawler_queue(user.id)
            
            users = crawlerqueue_repository.get_crawler_queues_status_false()
    else:
        rprint(f"‚ùå Kh√¥ng th·ªÉ thu th·∫≠p d·ªØ li·ªáu t·ª´ ng∆∞·ªùi d√πng ch√≠nh ‚ùå")

@app.command()
def display_queue() -> None:
    queue_data = crawlerqueue_repository.get_crawler_queues_status_false()
    if len(queue_data) == 0:
        rprint("[bold] Queue is empty. [/bold]")
    else:
        rprint(
            f"[bold] Found {len(queue_data)} queue objects with status False: [/bold]"
        )
        for queue in queue_data:
            rprint(f"- [bold] ID: {queue.id} [/bold] {queue.url}")

@app.command()
def delete_queue_object(
    id: Annotated[int, typer.Argument(help="CrawlerQueue id")]
) -> None:
    if crawlerqueue_repository.delete_crawler_queue(id):
        rprint("‚úÖ Queue object deleted ‚úÖ")
    else:
        rprint("‚ùåFailed to delete Queue object from database. Please try again.‚ùå")

@app.command()
def clear_queue() -> None:
    delete = crawlerqueue_repository.delete_all()
    if delete:
        rprint("‚úÖ Queue cleared ‚úÖ")
    else:
        rprint("‚ùåQueue not cleared, please try again‚ùå")

@app.command()
def login_2_step() -> None:
    facebook = FacebookLogIn()

    time_start = time()
    facebook.login_2_step_pipeline()
    time_end = time()

    if facebook.is_pipeline_successful:
        rprint(f"‚úÖLogging successful after {time_end - time_start} seconds ‚úÖ")
    else:
        rprint(f"‚ùåLogging failed after {time_end - time_start} seconds ‚ùå")

@app.command()
def login() -> None:
    facebook = FacebookLogIn()

    time_start = time()
    facebook.login_no_verification_pipeline()
    time_end = time()

    if facebook.is_pipeline_successful:
        rprint(f"‚úÖLogging successful after {time_end - time_start} seconds ‚úÖ")
    else:
        rprint(f"‚ùåLogging failed after {time_end - time_start} seconds ‚ùå")

@app.command()
def friend_layer_crawler(
    user_id: Annotated[str, typer.Argument(help="Facebook user id")]
) -> None:
    max_layers = typer.prompt(
        "üìè Nh·∫≠p s·ªë t·∫ßng c·∫ßn crawl (0 = ch·ªâ l·∫•y b·∫°n b√® tr·ª±c ti·∫øp)",
        type=int
    )

    friends_per_layer = []
    for i in range(max_layers + 1):
        num = typer.prompt(f"üî¢ Nh·∫≠p s·ªë b·∫°n b√® c·∫ßn l·∫•y ·ªü t·∫ßng {i}", type=int)
        if num <= 0:
            typer.echo("‚ùå S·ªë l∆∞·ª£ng b·∫°n b√® ph·∫£i l·ªõn h∆°n 0")
            return
        friends_per_layer.append(num)

    typer.echo(f"\nüìã Th√¥ng tin crawl:")
    typer.echo(f"- S·ªë t·∫ßng: {max_layers}")
    typer.echo(f"- S·ªë b·∫°n b√® m·ªói t·∫ßng: {friends_per_layer}")

    # T√≠nh to√°n chi ti·∫øt s·ªë l∆∞·ª£ng t√†i kho·∫£n ·ªü m·ªói t·∫ßng
    layer_accounts = []  # S·ªë t√†i kho·∫£n th·ª±c t·∫ø ·ªü m·ªói t·∫ßng
    
    typer.echo(f"\nüìà D·ª± ki·∫øn s·ªë l∆∞·ª£ng t√†i kho·∫£n:")
    
    # T·∫ßng 0: s·ªë b·∫°n b√® l·∫•y t·ª´ ID g·ªëc
    accounts_layer_0 = friends_per_layer[0]
    layer_accounts.append(accounts_layer_0)
    typer.echo(f"- T·∫ßng 0: {accounts_layer_0} t√†i kho·∫£n (b·∫°n b√® c·ªßa ID g·ªëc)")
    
    # T√≠nh s·ªë t√†i kho·∫£n cho c√°c t·∫ßng ti·∫øp theo
    for layer in range(1, max_layers + 1):
        # T·ª´ m·ªói t√†i kho·∫£n t·∫ßng tr∆∞·ªõc l·∫•y friends_per_layer[layer] b·∫°n b√®
        accounts_in_layer = layer_accounts[layer - 1] * friends_per_layer[layer]
        layer_accounts.append(accounts_in_layer)
        typer.echo(f"- T·∫ßng {layer}: {layer_accounts[layer - 1]} x {friends_per_layer[layer]} = {accounts_in_layer} t√†i kho·∫£n")
    
    total_accounts = sum(layer_accounts)
    typer.echo(f"\nüéØ T·ªïng s·ªë t√†i kho·∫£n d·ª± ki·∫øn: {total_accounts}")
    
    # Hi·ªÉn th·ªã chi ti·∫øt t√≠nh to√°n
    calculation_parts = [str(count) for count in layer_accounts]
    typer.echo(f"üí° Chi ti·∫øt: {' + '.join(calculation_parts)} = {total_accounts}")

    if not typer.confirm("‚ùì B·∫°n c√≥ mu·ªën ti·∫øp t·ª•c kh√¥ng?"):
        return

    rprint(f"\nüöÄ B·∫Øt ƒë·∫ßu crawl d·ªØ li·ªáu t·ª´ [bold]{user_id}[/bold] v·ªõi {max_layers} t·∫ßng")
    crawler = AccountFriendLayer(user_id, max_layers, friends_per_layer)
    crawler.crawl()